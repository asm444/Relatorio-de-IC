	\chapter*{Análise dos códigos}
\addcontentsline{toc}{chapter}{Análise dos códigos}



\begin{comment}		%Apresentação das bibliotecas, citar as passagem dos sites.
	As análises foram realizadas em um ambiente com uma distribuição Linux baseado em Debian, o Ubuntu e pode ser realizada em qualquer ambiente Linux sem dificuldades com algumas adaptações. A instalação do CCL é simples, consulte as instruções da  \textit{\href{https://ccl.readthedocs.io/en/latest/source/installation.html}{\color{blue}instalação}} do CCL, mas antes instale as dependências, os pacotes \textit{SWIG} e \textit{cmake}, utilizando o gerenciador de pacotes do python. Já a instalação da biblioteca da NumCosmo, consulte as instruções da \textit{\href{https://numcosmo.github.io/download/}{\color{blue}instalação}} da NumCosmo, a orientação de instalação depende da distribuição Linux utilizada.
\section*{CCL - Core Cosmology Library}
O \href{https://ccl.readthedocs.io/en/latest/?badge=latest#core-cosmology-library}{\color{blue}CCL} ( Core Cosmology Library) é uma biblioteca padronizada de cosmologia que fornece rotinas para computar observáveis cosmológicos básico com alta precisão e foi verificada com um amplo conjunto de testes de validação (\textit{brenchmarks}). As previsões são fornecidas para muitas grandezas cosmológicas, incluindo distâncias, espectro de potência angular, funções de correlação e entre outras  \href{https://arxiv.org/abs/1812.05995}{\color{blue}suportadas}. 

O CCL é escrita em C e Python, com os códigos de cálculo numérico escrito em C e a orientação a objeto escrita em Python, possuindo uma API pública em python sem a necessidade da alteração na interface em C, em um pacote python, o \textit{pyccl}, com módulos intuitivos que permitem computar diversas grandezas cosmológicas suportadas, consulte a   \href{https://ccl.readthedocs.io/en/latest/api/modules.html}{\color{blue}documentação} do CCL.

\section*{NumCosmo}

NumCosmo é uma biblioteca C de software livre cujo objetivo principal é testar modelos cosmológicos usando dados observacionais e fornecer um conjunto de ferramentas para realizar cálculos cosmológicos. A \href{https://numcosmo.github.io/about/}{\color{blue}NumCosmo}  é escrita em C, possui orientação a objeto através do framework \textit{GObject} e\cite{virtualizacao2014} compatibilidade para linguagens que suportam introspecção Gobject, como Python, Perl e entre outros. 
\end{comment}

\section*{O algoritmo de validação}

Para realizar a comparação entre as observáveis, foi utilizado como base um dos algoritmos do conjunto de teste de validação do CCL, o algoritmo de verificação dos cálculos de correlações cruzadas escrito em python chamado  \textit{test\_correlation.py}.

Este algoritmo consulta um conjunto de dados de redshift, o espectro de potência angular, contraste de densidade de matéria, multipolos correspondentes ao espectro de potência de entrada, spin e entre outras grandezas cosmológicas para inicializar os traçadores, ou seja, as funções de correlação cruzadas. Ele calcula o valor da função de correlação para as separações angulares fornecidas como entrada e verifica a coerência do resultado comparando com o valor do erro de cálculo estimulado.

O algoritmo utiliza a estrutura de testes escalonáveis do módulo \textit{pytest} para validar os cálculos em 112 testes utilizando três traçadores:  \textit{NumberCountsTracer}, \textit{WeakLensingTracer} e \textit{CMBLensingTracer}. Os testes foram feitos com os métodos: \textit{fftlog} (Transformações rápidas de Fourier que permite menos custo computacional de processamento do que computar integrações de força bruta nos cálculos), \textit{bessel} (método de cálculo utilizando as funções esféricas de Bessel), já para o método \textit{legendre} (Soma da força bruta sobre os polinômios de Legendre) não possui testes implementados.

O algoritmo consulta 35 arquivos com extensão \textit{.txt} contendo o conjunto de dados, mas apenas quatro arquivos são utilizados para realizar os cálculos dos observáveis e 31 arquivos são consultados para calcular o erro estimado e validar cada um dos cálculos realizados. O algoritmo possui um problema relativamente simples de implementação relacionado a declaração do endereço do diretório dos arquivos, onde é preciso realizar uma alteração no código para que o teste de validação funcione corretamente. 

Um dos interesses deste trabalho era utilizar os testes com o traçador \textit{CMBLensingTracer}, ou observáveis com spin-0 utilizando outros traçadores, afim de comparar os resultados do teste com os resultados computados pela NumCosmo utilizando os mesmos conjuntos de dados e verificar o grau de concordância entre as bibliotecas sobre esses resultados, mas infelizmente, nenhum teste com essas condições foi implementado neste algoritmo. A NumCosmo ainda não possui suporte para observáveis com spin diferente de zero e, portanto, dentre os testes do algoritmo de validação, apenas os testes utilizando o traçador  \textit{NumberCountsTracer} e o spin-0 permitem efetuar a análise. O algoritmo possui suporte para computar tanto os casos analíticos quanto os casos de histograma, como os cálculos de casos analíticos não foram implementados na NumCosmo, este trabalho aborda apenas casos com  os dados de histograma para a comparação entre bibliotecas, mas este fato não impede de realizarmos a comparação dos métodos diferentes em casos analíticos feitos pelo CCL.

Ao adaptar o teste que utiliza o traçador \textit{NumberCountsTracer} e observáveis com spin-0 em um \textit{jupyter notebook} descartando a dependência da consulta dos 31 arquivos de validação dos resultados, a inicialização de outros traçadores e seus respectivos cálculos, surgem dois desafios sobre a estrutura do código para a implementação, que seria remover a dependência do módulo \textit{pytest} e da consulta do conjunto de dados. A estrutura de testes escalonáveis do módulo \textit{pytest} é incompatível com o tipo de análise que precisamos e a consulta em vários arquivos não é interessante, pois o conjunto de dados é relativamente pequeno e podemos evitar as complicações relacionadas a manipulação de arquivos, em outras palavras, buscamos a produção de um algoritmo simples sem complicações/problemas a mais para lidar.

Com auxílio de algoritmos simples escritos em python, aproveitamos a versatilidade da linguagem para extrair os dados dos arquivos consultados e agrupamos em uma coleção ordenada dos dados nas listas dentro do \textit{jupyter notebook}, com um estudo detalhado do comportamento do algoritmo e suas diversas funções escalonadas no teste e várias tentativas de sintetizar o código, foi possível simplificar todas as funções do algoritmo em apenas uma função, com poucas entradas, eliminando as verificações de envio de parâmetro inválidos e com os mesmos resultados que o algoritmo original apresentava.

Para a produção dos gráficos de distâncias relativas entre resultados, reaproveitamos uma função de comparação de resultados entre o CCL e a NumCosmo, ela é responsável por construir dois gráfico organizados na horizontal, onde o primeiro apresentava as curvas dos resultados de ambas as bibliotecas e o segundo apresentava a curva da distância relativa de seus resultados. A função estava definida no \textit{jupyter notebook} presente no repositório da NumCosmo chamado \textit{NumCosmoCCLTest.ipynb}, onde apresentava a comparação dos resultados computados de distância e espectro de potência de ambas as bibliotecas, demostrando a discordância/concordância de seus cálculos.

Após o tratamento do algoritmo com os dados computados pelo CCL, desenvolvemos um estudo sobre a implementação dos códigos da NumCosmo ao estudar, documentar e separar os códigos anteriores do arquivo \textit{NumCosmoCCLTest.ipynb} em três arquivos que realizam a comparação dos resultados de distância, espectro de potência e o que produzimos sobre correlações cruzadas entre as bibliotecas.











